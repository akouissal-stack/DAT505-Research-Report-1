---
title: "RR1 draft H1"
format: 
  html:
    self_contained: true
    toc: true
    toc-depth: 2
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: visual
author: Ouissal Akioui
---

## Introduction

The analysis presented in this paper relies on the Moroccan News Articles Dataset (MNAD), a large-scale corpus of Arabic news articles collected from major Moroccan online news outlets. The MNAD corpus was introduced to address the scarcity of high-quality, large-scale resources for Arabic text analysis and news categorization. It contains more than 418,000 articles distributed across 19 thematic categories. Each article is structured around three core elements: a title, a body of text, and a category label. This structure makes the dataset particularly well suited for text-as-data approaches that aim to compare discursive patterns across sources while maintaining a consistent unit of analysis at the article level.

The MNAD corpus aggregates content from four Moroccan online news outlets—Akhbarona, Hespress, Hibapress, and Le360—each of which exhibits distinct editorial practices, publication styles, and degrees of institutional proximity. While these outlets operate within the same national media environment, they differ in tone, framing, and communicative conventions, as well as owners and audiences, making them a relevant case for comparative analysis of media discourse.

Given the thematic diversity of the dataset, this study deliberately restricts the analysis to articles classified under the *Culture* category. This choice is methodological rather than substantive. News categories such as politics, economics, or sports are associated with structurally different emotional registers and rhetorical constraints, which would confound comparisons of tone across sources. Focusing on cultural coverage allows the analysis to hold the topic of discussion relatively constant, thereby isolating variation in sentiment that is more plausibly attributable to editorial and discursive choices rather than to differences in subject matter.

To move beyond descriptive statistics, the analysis adopts a text-as-data framework in which sentiment analysis is used as a measurement tool rather than as an explanatory model. Sentiment scores are computed at the article level, transforming textual content into continuous numerical variables that capture the overall emotional tone of both titles and article bodies. These sentiment measures are then used as dependent variables in statistical models designed to examine systematic differences across news sources.

Rather than claiming to directly measure “state discourse,” the analysis treats sentiment tone as a proxy for broader discursive patterns commonly associated with institutional communication, such as emotional restraint, neutrality, or formalization. This approach allows for a cautious and analytically grounded examination of how institutional positioning may shape media tone, without conflating sentiment with intent or ideology.

In addition to overall sentiment, the study will also consider the relationship between title sentiment and body sentiment. Headlines play a central role in framing and audience engagement, and differences between title and body tone may reflect distinct editorial strategies. Comparing this gap across sources provides further insight into how emotional emphasis is distributed within articles.

Based on this analytical framework, the study advances the following hypotheses:

**H1 — Institutional Tone Hypothesis**

News sources that are more institutionally aligned are expected to display more neutral sentiment in cultural articles compared to less institutionally aligned sources.\
The rationale is that institutionally proximate outlets tend to favor emotionally restrained discourse, even outside explicitly political domains.

**H2 — Source Differences in Sentiment**\
Within the *Culture* category, the average sentiment of news articles differs across news sources.\
This hypothesis tests whether Moroccan news outlets exhibit distinct tonal profiles in cultural reporting, reflecting differences in editorial style and communicative norms.

## Hypothesis 1

### Descriptive Analyses

```{r}
rm(list=ls()) #This line of code cleans the environment

# Load libraries (or packages):
library(tidyverse) 
library(dplyr)

#Load the datasets:
hespress <- read_csv("Hespress.ma.csv", show_col_types = FALSE)

View(hespress)
```

```{r}

library(dplyr)
library(stringr)

hespress_culture <- hespress %>%
  mutate(Category = str_trim(Category)) %>%  
  filter(Category == "Culture")

View(hespress_culture)

```

#### Tokenization and stopwords

```{r}
library(dplyr)
library(tidyr)
library(tidytext)

hespress_culture <- hespress_culture %>%
  mutate(doc_id = row_number())

tokens_body <- hespress_culture %>%
  select(doc_id, Body) %>%
  unnest_tokens(
    output   = word,
    input    = Body,
    token    = "words",
    to_lower = FALSE
  )

tokens_title <- hespress_culture %>%
  select(doc_id, Title) %>%
  unnest_tokens(
    output   = word,
    input    = Title,
    token    = "words",
    to_lower = FALSE
  )

```

```{r}
library(stopwords)
#using an already built dictionary but also adding manually

arabic_sw <- stopwords(language = "ar", source = "misc")

manual_sw <- c(
  "عبد",
  "عبر",
  "علي",
  "الي",
  "وذلك",
  "المائة",
  "ذاته",
  "فيما",
  "اخري",
  "اذ",
  "حتى",
  "إلى",
  "بـ",
  "أن",
  "إلا",
  "يذكر",
  "داخل"
)

# combine with existing Arabic stopwords
all_sw <- unique(c(arabic_sw, manual_sw))

# apply cleaning (no re-tokenizing)
tokens_title_clean <- tokens_title %>%
  filter(
    !word %in% all_sw,
    str_length(word) >= 2
  )

# check top words
tokens_title_clean %>%
  count(word, sort = TRUE) %>%
  slice_head(n = 20)
```

You’re looking at the **20 most frequent words in article titles** in the *culture* corpus. The dominant terms are: **National identifiers**, **Cultural domains**, **Institutional / symbolic references**, **Generic evaluative markers.** This frequency distribution indicates that cultural coverage is **strongly anchored in national identity and institutional cultural production**, rather than personal or emotive framing.

#### Bigrams

```{r}
library(tidytext)
library(dplyr)
library(stringr)

bigrams <- hespress_culture %>%
  select(doc_id, Body) %>%
  unnest_tokens(
    output = bigram,
    input  = Body,
    token  = "ngrams",
    n      = 2
  ) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ") %>%
  filter(
    !word1 %in% all_sw,
    !word2 %in% all_sw,
    str_length(word1) > 1,
    str_length(word2) > 1
  ) %>%
  unite(bigram, word1, word2, sep = " ")


```

```{r}
bigram_freq <- bigrams %>%
  count(bigram, sort = TRUE) %>%
  slice_head(n = 20)
knitr::kable(bigram_freq, col.names = c("Bigram", "Frequency"))

```

The most frequent bigrams in *Hespress* culture articles are overwhelmingly **institutional, national, and formal**.

The most frequent bigrams in Hespress culture articles are dominated by institutional and national references, such as “وزارة الثقافة” (906), “محمد السادس” (845), and “وزير الثقافة” (513), as well as formal journalistic constructions like “تصريح لهسبريس” (753). Cultural coverage is thus framed primarily around official actors, state institutions, and nationally symbolic figures and events.

```{r}
library(ggplot2)

bigram_freq %>%
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top 20 bigrams in Hespress culture articles",
    x = NULL,
    y = "Frequency"
  ) +
  theme_minimal()

```

```{r}
bigram_edges <- hespress_culture %>%
  unnest_tokens(bigram, Body, token = "ngrams", n = 2) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ") %>%
  filter(
    !word1 %in% all_sw,
    !word2 %in% all_sw,
    str_length(word1) > 1,
    str_length(word2) > 1
  ) %>%
  count(word1, word2, sort = TRUE) %>%
  slice_head(n = 30)

bigram_edges

```

The bigram network of culture articles reveals a fragmented structure organized around institutional actors, national identifiers, and formal cultural sectors rather than affective or experiential language. Clusters centered on state institutions, official figures, and organized cultural production dominate the network, while no emotionally charged hub emerges.

```{r}
library(ggplot2)
ggplot(bigram_edges,
       aes(x = word1, y = word2, fill = n)) +
  geom_tile(color = "white") +
  scale_fill_gradient(
    low = "#fee090",
    high = "#d73027"
  ) +
  theme_minimal() +
  labs(
    title = "Bigram Co-occurrence Heatmap",
    x = "First word",
    y = "Second word",
    fill = "Count"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

```{r}
library(dplyr)
library(igraph)

# ---- TUNING KNOBS (change these if needed) ----
TOP_EDGES   <- 20   # try 15–25
MIN_N       <- 2    # keep edges with count >= this
LABEL_TOP_N <- 12   # number of nodes to label

# 1) filter edges to reduce clutter
edges_plot <- bigram_edges %>%
  filter(n >= MIN_N) %>%
  slice_max(n, n = TOP_EDGES, with_ties = FALSE)

# 2) build graph (UNDIRECTED for readability)
g <- graph_from_data_frame(edges_plot, directed = FALSE)
E(g)$weight <- edges_plot$n

# 3) sizes / widths
s <- strength(g, mode = "all", weights = E(g)$weight)
V(g)$size  <- 8 + 18 * (s / max(s))

w <- E(g)$weight
E(g)$width <- 1 + 6 * (w / max(w))

# 4) colors (edge color by weight gradient)
edge_pal <- colorRampPalette(c("#9ecae1", "#fdae61", "#de2d26"))
E(g)$color <- edge_pal(100)[cut(w, breaks = 100, include.lowest = TRUE)]

V(g)$color <- "#2b8cbe"
V(g)$frame.color <- "white"

# 5) label ONLY the most important nodes
top_nodes <- names(sort(s, decreasing = TRUE))[seq_len(min(LABEL_TOP_N, length(s)))]
V(g)$label <- ifelse(V(g)$name %in% top_nodes, V(g)$name, NA)
V(g)$label.cex <- 1.1
V(g)$label.color <- "black"
V(g)$label.dist <- 0.8

# 6) layout (more iterations = less overlap)
set.seed(123)
L <- layout_with_fr(g, niter = 2000)

par(mar = c(0, 0, 2, 0))
plot(
  g,
  layout = L,
  edge.curved = 0.15,
  main = paste0("Bigram Network (Top ", TOP_EDGES, ", n≥", MIN_N, ")")
)
```

#### TF–IDF

The TF–IDF analysis highlights terms that are particularly distinctive to individual cultural articles, rather than words that are frequent across the corpus as a whole. High TF–IDF scores correspond to terms that appear repeatedly within a given article but remain relatively rare in other cultural coverage. As such, these terms often reflect article-specific topics, events, or concepts, illustrating the heterogeneity of cultural content published by Hespress.

The TF–IDF analysis reveals that cultural articles published by Hespress are characterized by a high degree of **lexical specialization at the article level**.

```{r}

library(tidytext)

tfidf <- tokens_body %>%
  count(doc_id, word, sort = TRUE) %>%
  bind_tf_idf(word, doc_id, n) %>%
  arrange(desc(tf_idf))

top_tfidf <- tfidf %>% slice_head(n = 20)
top_tfidf

library(ggplot2)

ggplot(top_tfidf, aes(x = reorder(word, tf_idf), y = tf_idf, fill = tf_idf)) +
  geom_col() +
  coord_flip() +
  scale_fill_gradient(low = "#9ecae1", high = "#de2d26") +
  labs(
    title = "Top TF–IDF terms (Hespress – Culture)",
    x = NULL,
    y = "TF–IDF score",
    fill = "TF–IDF"
  ) +
  theme_minimal()


```

The dominance of terms related to **artistic genres (هايكو، مسرح، سينما)**, **professional or technical fields (هندسة، توليد، الأعمال)**, and **abstract or institutional registers (السياسي، الاقتصاد)** suggests that Hespress’ cultural articles are **not built around generic cultural talk** or affective language. Instead, each article is anchored in a **clearly delimited thematic frame**, often analytical or domain-specific.

In other words, cultural coverage appears **heterogeneous but structured**: articles focus on distinct cultural objects, practices, or debates, using specialized vocabularies rather than a shared set of recurring “cultural” keywords. High TF–IDF values here therefore reflect an **editorial style oriented toward contextualization and interpretation**.

#### Lexical diversity

The corpus contains approximately **2.9 million tokens** and **223,062 unique word types**, yielding a **type–token ratio (TTR) of 0.077**. This relatively low TTR is expected for a large-scale news corpus, as the denominator (total tokens) increases much faster than the number of new word types. Substantively, this indicates a **high degree of lexical repetition**, driven by the recurrent use of common vocabulary across articles.

```{r}
library(knitr)
lex_div <- tokens_body %>%
  summarise(
    total_words = n(),
    unique_words = n_distinct(word),
    type_token_ratio = unique_words / total_words
  )

kable(lex_div, digits = 3)


```

### Sentiment Analysis

Cultural articles that engage more directly with institutional actors or formal domains are expected to display a more emotionally restrained tone, reflected in lower sentiment intensity, compared to culturally oriented articles that lack institutional framing.

To test this hypothesis, we will will need:

1.  **Sentiment score per article**

2.  **Institutional proximity measure per article**

```         
binary (institutional vs not) 
```

3.  **Sentiment intensity** `abs(sentiment_score)`

4.  A comparison: descriptive and regression (optional but good)

Sentiment analysis was implemented in Python using the pre-trained **CAMeL-Lab Arabic BERT model for sentiment analysis** (bert-base-arabic-camelbert-da-sentiment) available on Hugging Face.

The base CAMeLBERT-DA model was pre-trained on a large corpus of dialectal Arabic web text, comprising approximately **54 GB of text (5.8 billion words)**. The sentiment analysis model does not introduce additional pre-training data, but instead fine-tunes this base model on manually annotated sentiment datasets (ASTD, ArSAS, SemEval), which include both dialectal and Modern Standard Arabic texts.

While the authors provide detailed information on corpus size and language variant, the exact genre composition of the dialectal Arabic training data is not exhaustively specified.

Article texts were tokenized and processed through this transformer-based model to generate document-level sentiment classifications, leveraging Python’s NLP ecosystem for efficient handling of large-scale text. Once each article received a sentiment score and intensity, the resulting dataset of scores was exported (e.g., as CSV) and re-imported into RStudio. In RStudio, these sentiment scores were merged with the original corpus metadata, enabling further descriptive analysis, statistical modeling, and visualization alongside other text features.

The sentiment model outputs probabilities over discrete sentiment classes (positive, negative, neutral). These probabilities are transformed into a continuous sentiment score defined as the difference between the predicted probability of positive sentiment and negative sentiment. Positive values indicate a positive tone, negative values indicate a negative tone, and values close to zero indicate neutrality or balance. Sentiment intensity is defined as the absolute value of this score and reflects the strength of sentiment regardless of direction.

```{r}
#we load the dataset with only the culture category to use it in python
write.csv(
  hespress_culture[, c("doc_id", "Body")],
  "hespress_culture_body.csv",
  row.names = FALSE
)

```

**Building the Institutional alignment proxy**

```{r}
library(dplyr)
library(stringr)

inst_terms <- c(
  # state / government core
  "الملك","القصر","الديوان الملكي","أمير المؤمنين",
  "الحكومة","رئيس الحكومة","الوزير","وزارة","البرلمان","مجلس النواب","مجلس المستشارين",
  "الأمانة العامة","الولاية","العمالة","العامل","الوالي","الجماعة","المجلس الجماعي",
  "الجهة","المجلس الجهوي",
  
  # justice / security
  "المحكمة","النيابة العامة","القضاء","المجلس الأعلى للسلطة القضائية",
  "الشرطة","الأمن","الدرك","القوات المسلحة","الجيش","القيادة","المخابرات",

  # public agencies / official bodies (common)
  "المندوبية","المفوضية","الهيئة","المجلس الوطني","المجلس الأعلى","مؤسسة عمومية","الوكالة","المرصد","اللجنة","اللجان",
  "وزارة الثقافة","مؤسسة ","وزارة التربية","وزارة التعليم","وزارة الصحة","وزارة الداخلية",

  # official discourse markers
  "بلاغ","بيان","تصريح رسمي","مصدر رسمي","وفق\\s+بلاغ","حسب\\s+بلاغ","أفاد\\s+بلاغ",
  "قرار","مرسوم","منشور","قانون","مشروع\\s+قانون","مذكرة"
)

```

```{r}
inst_regex <- str_c(inst_terms, collapse = "|")
# Combine all institutional terms into a single regex pattern to match any of them in the text
```

```{r}
# Build a single text field by concatenating Title + Body (handling missing values),
# then count how many institutional keywords appear (inst_hits),
# and flag the article as "institutional" if it contains at least 2 hits.
hespress_culture <- hespress_culture %>%
  mutate(
    Body = str_c(coalesce(Title, ""), " ", coalesce(Body, "")),
    inst_hits = str_count(Body, inst_regex),
    institutional_article = inst_hits >= 2
  )

```

```{r}
# Check how many articles contain at least one institutional keyword,
# and summarize the distribution of keyword counts per article.
table(hespress_culture$institutional_article)
summary(hespress_culture$inst_hits)

```

Articles are classified as institutional if they contain **at least two institutional keyword occurrences**, which is intended to capture sustained rather than incidental institutional language. Under this definition, 3,168 articles are flagged as institutional, while 4,641 articles contain zero or one institutional keyword and are classified as non-institutional.

Institutional keyword counts are generally low across the corpus. The median number of hits is one, and 75% of articles contain three or fewer institutional keywords, indicating that most cultural articles either do not reference institutions or do so only minimally. The mean count (≈2.18) exceeds the median due to a strongly right-skewed distribution driven by a small number of articles with many institutional references, with extreme cases reaching up to 69 hits. Overall, this pattern suggests that sustained institutional framing is present in a substantial minority of articles but is not the dominant mode of discourse in cultural reporting.

```{r}
boxplot(
  hespress_culture$inst_hits,
  main = "Distribution of Institutional Keyword Counts",
  ylab = "Number of institutional keyword hits",
  col = "lightgray"
)

```

The institutional keyword count is highly skewed and concentrated near zero, with a small number of extreme outliers, making a continuous specification unstable and difficult to interpret. Most observations are concentrated at very low values, with the median close to one institutional keyword and a narrow interquartile range near zero. In contrast, a small number of articles display exceptionally high counts, producing a long right tail with extreme outliers.

```{r}
boxplot(
  log1p(hespress_culture$inst_hits),
  main = "Log-Scaled Institutional Keyword Counts",
  ylab = "log(1 + institutional hits)",
  col = "lightgray"
)

```

While institutional keyword counts are highly concentrated near zero, this feature of the data motivates rather than undermines the use of a binary indicator, which captures the presence of sustained institutional language without relying on fragile continuous variation.

**Merging the datasets**

Now, back to reuploading our ready to go sentiment analysis dataset.

```{r}
library(dplyr)
library(readr)

sentiment_df <- read_csv(
  "hespress_sentiment_transformer.csv",
  show_col_types = FALSE
)
View(sentiment_df)
```

```{r}
#we merge with our existing dataset
hespress_culture <- hespress_culture %>%
  left_join(sentiment_df, by = "doc_id")
```

```{r}
#checking for NAs and such
summary(hespress_culture$sentiment_score)
sum(is.na(hespress_culture$sentiment_score))

```

-   Intepretation

-   **No missing values**: the NA count is 0, so sentiment scores are available for all articles.

-   The sentiment score spans almost the full theoretical range, from **−0.997 to +0.996**, indicating that the model assigns both strongly negative and strongly positive sentiment to some articles.

-   The **median is exactly 0**, which suggests that the typical cultural article is sentimentally neutral, or that positive and negative sentiment probabilities are closely balanced for most texts.

-   The **mean is slightly positive (≈ 0.04)**, indicating a small overall tilt toward positive sentiment across the corpus, though the magnitude is modest.

-   The interquartile range (from about −0.36 to +0.46) shows that the middle 50% of articles exhibit mild sentiment, with relatively few extreme values.

Overall, this distribution suggests that Hespress culture articles are predominantly neutral in tone, with limited polarization and only a small subset exhibiting strong positive or negative sentiment.

```{r}
hist(
  hespress_culture$sentiment_score,
  breaks = 40,
  main = "Distribution of Sentiment Scores",
  xlab = "Sentiment score"
)

```

The distribution of sentiment scores is highly concentrated around zero, with a large mass of neutral observations and relatively fewer strongly positive or negative cases. This non-normal, bounded distribution is consistent with the construction of the sentiment measure and reflects the predominantly neutral tone of cultural reporting.

Because the sentiment score is bounded and derived from class probabilities, departures from normality are expected and do not invalidate linear modeling of conditional mean differences.

#### **Quick descriptive check**

```{r}
hespress_culture %>%
  group_by(institutional_article) %>%
  summarise(
    mean_sentiment = mean(sentiment_score, na.rm = TRUE),
    sd_sentiment   = sd(sentiment_score, na.rm = TRUE),
    n = n()
  )

```

We first split the Hespress culture articles into two groups using the binary institutional proxy (`institutional_article`). Articles coded **FALSE** are those with **0–1 institutional keyword hits** (i.e., institution-light or only incidental mentions). Articles coded **TRUE** are those with **≥ 2 institutional keyword hits**, which we treat as indicating **sustained institutional language**.

Next, we computed the **mean sentiment score**, the **standard deviation**, and the **number of observations** in each group. The institution-light group (**FALSE**) contains **4,641** articles and has an average sentiment score of **0.086** (SD = **0.551**), suggesting a slightly positive tone on average. The institution-heavy group (**TRUE**) contains **3,168** articles and has a lower average sentiment score of **−0.019** (SD = **0.529**), indicating a more neutral-to-slightly negative tone.

Overall, the descriptive comparison shows that articles with sustained institutional language have **lower average sentiment** than those with minimal institutional references (a raw mean difference of roughly **0.10** points), even before introducing controls such as article length.

```{r}
library(ggplot2)

ggplot(hespress_culture,
       aes(x = institutional_article,
           y = sentiment_score,
           fill = institutional_article)) +
  geom_violin(alpha = 0.6) +
  geom_boxplot(width = 0.15, outlier.shape = NA, fill = "white") +
  scale_x_discrete(
    labels = c("0–1 institutional hits", "≥ 2 institutional hits")
  ) +
  scale_fill_manual(
    values = c("FALSE" = "#B0C4DE", "TRUE" = "#4682B4")
  ) +
  labs(
    title = "Distribution of Sentiment by Institutional Framing",
    x = "Institutional framing",
    y = "Sentiment score"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


```

This figure presents a violin plot with embedded boxplots showing the distribution of sentiment scores for institution-light and institution-heavy articles. Descriptively, sentiment distributions overlap substantially across institutional and non-institutional articles, although institutional articles exhibit a slight downward shift toward neutrality.

Conclusion: Taken together, the initial descriptive analyses provide **limited but directionally consistent support** for the hypothesis. While the sentiment distributions of institution-light and institution-heavy articles overlap substantially, articles containing sustained institutional language exhibit **slightly lower average sentiment scores** and a modest shift toward neutrality. The absence of a pronounced visual separation suggests that any association between institutional framing and sentiment is **small in magnitude**, but the consistent downward shift in central tendency motivates further analysis. Accordingly, regression models are required to assess whether this relationship persists once controlling for article length and potentially other confounding factors.

### **Testing H1**

#### T-tests and Linear Model

A Welch two-sample t-test indicates a statistically significant difference in mean sentiment between institution-light and institution-heavy culture articles (t = 8.53, df = 6987.2, p \< 2.2×10⁻¹⁶). Institution-light articles (0–1 institutional hits) have a higher mean sentiment (M = 0.086) than institution-heavy articles (≥2 hits; M = −0.019). The estimated mean difference (M_FALSE − M_TRUE) is 0.106, with a 95% confidence interval of \[0.081, 0.130\], indicating a small but reliably positive difference in average sentiment. Because this comparison is bivariate, subsequent regression models are used to assess whether the association persists after controlling for article length.

```{r}
t.test(
  sentiment_score ~ institutional_article,
  data = hespress_culture
)

```

**Regression**

We estimate a linear regression model in which sentiment is regressed on institutional framing, controlling for article length. Article length is included to account for differences in textual verbosity that may mechanically affect sentiment scores.

Article length is included as a control variable because longer texts tend to exhibit lower sentiment scores, both mechanically and substantively. Mechanically, longer articles contain a higher proportion of neutral and informational language, which dilutes emotionally valenced content and pulls sentiment scores toward zero. Substantively, institutional density is itself correlated with article length, as institutionally framed articles typically provide more background and procedural detail. Controlling for article length therefore allows the effect of institutional density on sentiment to be interpreted independently of differences in text length.

```{r}
model1 <- lm(
  sentiment_score ~ institutional_article + n_words,
  data = hespress_culture
)

summary(model1)

```

Interpretation here

**Assumption checks**

Normality of residuals

Histogram of residuals

The shape is **not bell-shaped** in a classical Gaussian sense. The histogram shows residuals centered around zero with a strong concentration near neutrality and bounded tails. While the distribution departs from perfect normality, this pattern is expected given the bounded and discretized nature of the sentiment score and the large sample size.

```{r}
hist(
  resid(model1),
  breaks = 40,
  main = "Histogram of Regression Residuals",
  xlab = "Residuals"
)

```

Q–Q plot

```{r}
qqnorm(resid(model1))
qqline(resid(model1), col = "red")

```

The Q–Q plot indicates approximate normality in the central portion of the residual distribution, with deviations in the tails, which is expected given the bounded sentiment outcome and large sample size.

The S-shaped curve indicates **non-normal tails**.

### Homoskedasticity (constant variance)

### Residuals vs fitted values plot 

```{r}
plot(
  fitted(model1),
  resid(model1),
  xlab = "Fitted values",
  ylab = "Residuals",
  main = "Residuals vs Fitted Values"
)
abline(h = 0, col = "red")

```

\
Is the variance of residuals similar across the two groups? Do institutional and non-institutional articles show similar dispersion around their group mean?

A residuals-versus-fitted plot shows two vertical bands corresponding to the binary predictor, with residuals centered around zero and comparable dispersion across groups, suggesting no major violation of the homoskedasticity assumption.

```{r}
library(lmtest)
bptest(model1)

```

**A Breusch–Pagan test was conducted as a robustness check; results are interpreted cautiously given the large sample size.**

A Breusch–Pagan test indicates heteroskedasticity in the residuals (BP = 11.32, p \< .001). Accordingly, all regression results are reported with heteroskedasticity-robust standard errors.

```{r}
library(sandwich)
library(lmtest)

coeftest(model1, vcov = vcovHC(model1, type = "HC1"))

```

## Linearity

Because your main predictor is binary, linearity is **mostly trivial**,

```{r}
library(stringr)
library(dplyr)

hespress_culture <- hespress_culture %>%
  mutate(
    Body = str_c(coalesce(Title, ""), " ", coalesce(Body, "")),
    n_words = str_count(Body, "\\S+")
  )

```

```{r}
# Keep only rows with complete data for the variables used in model1
keep <- complete.cases(hespress_culture[, c("sentiment_score", "institutional_article", "n_words")])

x <- hespress_culture$n_words[keep]
y <- resid(model1)[keep]   # aligned to the same rows

plot(
  x, y,
  xlab = "Article length (words)",
  ylab = "Residuals",
  main = "Residuals vs Article Length"
)
abline(h = 0, col = "red")

```

## Independence

There is **no statistical test** here. Articles are treated as independent observations.
