---
title: "RR1 draft H1"
format: 
  html:
    self_contained: true
    toc: true
    toc-depth: 2
    embed-resources: true
execute:
  echo: true
  warning: false
  message: false
editor: visual
author: Ouissal Akioui
---

## Introduction

The analysis presented in this paper relies on the Moroccan News Articles Dataset (MNAD), a large-scale corpus of Arabic news articles collected from major Moroccan online news outlets. The MNAD corpus was introduced to address the scarcity of high-quality, large-scale resources for Arabic text analysis and news categorization. It contains more than 418,000 articles distributed across 19 thematic categories. Each article is structured around three core elements: a title, a body of text, and a category label. This structure makes the dataset particularly well suited for text-as-data approaches that aim to compare discursive patterns across sources while maintaining a consistent unit of analysis at the article level.

The MNAD corpus aggregates content from four Moroccan online news outlets—Akhbarona, Hespress, Hibapress, and Le360—each of which exhibits distinct editorial practices, publication styles, and degrees of institutional proximity. While these outlets operate within the same national media environment, they differ in tone, framing, and communicative conventions, as well as owners and audiences, making them a relevant case for comparative analysis of media discourse.

Given the thematic diversity of the dataset, this study deliberately restricts the analysis to articles classified under the *Culture* category. This choice is methodological rather than substantive. News categories such as politics, economics, or sports are associated with structurally different emotional registers and rhetorical constraints, which would confound comparisons of tone across sources. Focusing on cultural coverage allows the analysis to hold the topic of discussion relatively constant, thereby isolating variation in sentiment that is more plausibly attributable to editorial and discursive choices rather than to differences in subject matter.

To move beyond descriptive statistics, the analysis adopts a text-as-data framework in which sentiment analysis is used as a measurement tool rather than as an explanatory model. Sentiment scores are computed at the article level, transforming textual content into continuous numerical variables that capture the overall emotional tone of both titles and article bodies. These sentiment measures are then used as dependent variables in statistical models designed to examine systematic differences across news sources.

Rather than claiming to directly measure “state discourse,” the analysis treats sentiment tone as a proxy for broader discursive patterns commonly associated with institutional communication, such as emotional restraint, neutrality, or formalization. This approach allows for a cautious and analytically grounded examination of how institutional positioning may shape media tone, without conflating sentiment with intent or ideology.

In addition to overall sentiment, the study will also consider the relationship between title sentiment and body sentiment. Headlines play a central role in framing and audience engagement, and differences between title and body tone may reflect distinct editorial strategies. Comparing this gap across sources provides further insight into how emotional emphasis is distributed within articles.

Based on this analytical framework, the study advances the following hypotheses:

**H1 — Institutional Tone Hypothesis**

News sources that are more institutionally aligned are expected to display more neutral sentiment in cultural articles compared to less institutionally aligned sources.\
The rationale is that institutionally proximate outlets tend to favor emotionally restrained discourse, even outside explicitly political domains.

**H2 — Source Differences in Sentiment**\
Within the *Culture* category, the average sentiment of news articles differs across news sources.\
This hypothesis tests whether Moroccan news outlets exhibit distinct tonal profiles in cultural reporting, reflecting differences in editorial style and communicative norms.

**H3 — Editorial Framing Hypothesis**\
The difference between title sentiment and body sentiment varies across news sources.\
This hypothesis captures variation in framing strategies, where some outlets may rely on more emotionally charged headlines relative to article content, while others maintain greater tonal consistency.

## Hypothesis 1

### Descriptive Analyses

```{r}
rm(list=ls()) #This line of code cleans the environment

# Load libraries (or packages):
library(tidyverse) 
library(dplyr)

#Load the datasets:
hespress <- read_csv("Hespress.ma.csv", show_col_types = FALSE)

View(hespress)
```

```{r}

library(dplyr)
library(stringr)

hespress_culture <- hespress %>%
  mutate(Category = str_trim(Category)) %>%  
  filter(Category == "Culture")

View(hespress_culture)

```

#### Tokenization and stopwords

```{r}
library(dplyr)
library(tidyr)
library(tidytext)

hespress_culture <- hespress_culture %>%
  mutate(doc_id = row_number())

tokens_body <- hespress_culture %>%
  select(doc_id, Body) %>%
  unnest_tokens(
    output   = word,
    input    = Body,
    token    = "words",
    to_lower = FALSE
  )

tokens_title <- hespress_culture %>%
  select(doc_id, Title) %>%
  unnest_tokens(
    output   = word,
    input    = Title,
    token    = "words",
    to_lower = FALSE
  )

```

```{r}
library(stopwords)
#using an already built dictionary but also adding manually

arabic_sw <- stopwords(language = "ar", source = "misc")

manual_sw <- c(
  "عبد",
  "عبر",
  "علي",
  "الي",
  "وذلك",
  "المائة",
  "ذاته",
  "فيما",
  "اخري",
  "اذ",
  "حتى",
  "إلى",
  "بـ",
  "أن",
  "إلا",
  "يذكر",
  "داخل"
)

# combine with existing Arabic stopwords
all_sw <- unique(c(arabic_sw, manual_sw))

# apply cleaning (no re-tokenizing)
tokens_title_clean <- tokens_title %>%
  filter(
    !word %in% all_sw,
    str_length(word) >= 2
  )

# check top words
tokens_title_clean %>%
  count(word, sort = TRUE) %>%
  slice_head(n = 20)
```

You’re looking at the **20 most frequent words in article titles** in the *culture* corpus. The dominant terms are: **National identifiers**, **Cultural domains**, **Institutional / symbolic references**, **Generic evaluative markers.** This frequency distribution indicates that cultural coverage is **strongly anchored in national identity and institutional cultural production**, rather than personal or emotive framing.

#### Bigrams

```{r}
library(tidytext)
library(dplyr)
library(stringr)

bigrams <- hespress_culture %>%
  select(doc_id, Body) %>%
  unnest_tokens(
    output = bigram,
    input  = Body,
    token  = "ngrams",
    n      = 2
  ) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ") %>%
  filter(
    !word1 %in% all_sw,
    !word2 %in% all_sw,
    str_length(word1) > 1,
    str_length(word2) > 1
  ) %>%
  unite(bigram, word1, word2, sep = " ")


```

```{r}
bigram_freq <- bigrams %>%
  count(bigram, sort = TRUE) %>%
  slice_head(n = 20)
knitr::kable(bigram_freq, col.names = c("Bigram", "Frequency"))

```

The most frequent bigrams in *Hespress* culture articles are overwhelmingly **institutional, national, and formal**.

The most frequent bigrams in Hespress culture articles are dominated by institutional and national references, such as “وزارة الثقافة” (906), “محمد السادس” (845), and “وزير الثقافة” (513), as well as formal journalistic constructions like “تصريح لهسبريس” (753). Cultural coverage is thus framed primarily around official actors, state institutions, and nationally symbolic figures and events. This institutionalized framing helps explain the predominantly neutral sentiment observed in the analysis, as such language prioritizes informational and legitimizing discourse over affective or personal expression.

```{r}
library(ggplot2)

bigram_freq %>%
  ggplot(aes(x = reorder(bigram, n), y = n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top 20 bigrams in Hespress culture articles",
    x = NULL,
    y = "Frequency"
  ) +
  theme_minimal()

```

```{r}
bigram_edges <- hespress_culture %>%
  unnest_tokens(bigram, Body, token = "ngrams", n = 2) %>%
  separate(bigram, into = c("word1", "word2"), sep = " ") %>%
  filter(
    !word1 %in% all_sw,
    !word2 %in% all_sw,
    str_length(word1) > 1,
    str_length(word2) > 1
  ) %>%
  count(word1, word2, sort = TRUE) %>%
  slice_head(n = 30)

bigram_edges

```

The bigram network of culture articles reveals a fragmented structure organized around institutional actors, national identifiers, and formal cultural sectors rather than affective or experiential language. Clusters centered on state institutions, official figures, and organized cultural production dominate the network, while no emotionally charged hub emerges. This structure helps explain the predominantly neutral sentiment observed in institutionalized cultural coverage, suggesting that sentiment patterns reflect the administrative and informational framing of culture rather than emotional engagement.

#### TF–IDF

The TF–IDF analysis highlights terms that are particularly distinctive to individual cultural articles, rather than words that are frequent across the corpus as a whole. High TF–IDF scores correspond to terms that appear repeatedly within a given article but remain relatively rare in other cultural coverage. As such, these terms often reflect article-specific topics, events, or concepts, illustrating the heterogeneity of cultural content published by Hespress.

The TF–IDF analysis reveals that cultural articles published by Hespress are characterized by a high degree of **lexical specialization at the article level**.

```{r}

library(tidytext)

tfidf <- tokens_body %>%
  count(doc_id, word, sort = TRUE) %>%
  bind_tf_idf(word, doc_id, n) %>%
  arrange(desc(tf_idf))

top_tfidf <- tfidf %>% slice_head(n = 20)
top_tfidf

library(ggplot2)

ggplot(top_tfidf, aes(x = reorder(word, tf_idf), y = tf_idf)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top TF–IDF terms (Hespress – Culture)",
    x = NULL,
    y = "TF–IDF score"
  ) +
  theme_minimal()

```

The dominance of terms related to **artistic genres (هايكو، مسرح، سينما)**, **professional or technical fields (هندسة، توليد، الأعمال)**, and **abstract or institutional registers (السياسي، الاقتصاد)** suggests that Hespress’ cultural articles are **not built around generic cultural talk** or affective language. Instead, each article is anchored in a **clearly delimited thematic frame**, often analytical or domain-specific.

In other words, cultural coverage appears **heterogeneous but structured**: articles focus on distinct cultural objects, practices, or debates, using specialized vocabularies rather than a shared set of recurring “cultural” keywords. High TF–IDF values here therefore reflect an **editorial style oriented toward contextualization and interpretation**.

#### Lexical diversity

The corpus contains approximately **2.9 million tokens** and **223,062 unique word types**, yielding a **type–token ratio (TTR) of 0.077**. This relatively low TTR is expected for a large-scale news corpus, as the denominator (total tokens) increases much faster than the number of new word types. Substantively, this indicates a **high degree of lexical repetition**, driven by the recurrent use of common vocabulary across articles.

```{r}
library(knitr)
lex_div <- tokens_body %>%
  summarise(
    total_words = n(),
    unique_words = n_distinct(word),
    type_token_ratio = unique_words / total_words
  )

kable(lex_div, digits = 3)


```

### Sentiment Analysis

Cultural articles that engage more directly with institutional actors or formal domains are expected to display a more emotionally restrained tone, reflected in lower sentiment intensity, compared to culturally oriented articles that lack institutional framing.

To test this hypothesis, we will will need:

1.  **Sentiment score per article**

2.  **Institutional proximity measure per article**

```         
binary (institutional vs not) or continuous (institutional term density)
```

3.  **Sentiment intensity** `abs(sentiment_score)`

4.  A comparison: descriptive and regression (optional but good)

Sentiment analysis was implemented in Python using the pre-trained **CAMeL-Lab Arabic BERT model for sentiment analysis** (bert-base-arabic-camelbert-da-sentiment) available on Hugging Face. Article texts were tokenized and processed through this transformer-based model to generate document-level sentiment classifications, leveraging Python’s NLP ecosystem for efficient handling of large-scale text. Once each article received a sentiment score and intensity, the resulting dataset of scores was exported (e.g., as CSV) and re-imported into RStudio. In RStudio, these sentiment scores were merged with the original corpus metadata, enabling further descriptive analysis, statistical modeling, and visualization alongside other text features.

```{r}
#we load the dataset with only the culture category to use it in python
write.csv(
  hespress_culture[, c("doc_id", "Body")],
  "hespress_culture_body.csv",
  row.names = FALSE
)

```

**Building the Institutional alignment proxy**

```{r}
library(dplyr)
library(stringr)

inst_terms <- c(
  # state / government core
  "الملك","القصر","الديوان الملكي","أمير المؤمنين",
  "الحكومة","رئيس الحكومة","الوزير","وزارة","البرلمان","مجلس النواب","مجلس المستشارين",
  "الأمانة العامة","الولاية","العمالة","العامل","الوالي","الجماعة","المجلس الجماعي",
  "الجهة","المجلس الجهوي",
  
  # justice / security
  "المحكمة","النيابة العامة","القضاء","المجلس الأعلى للسلطة القضائية",
  "الشرطة","الأمن","الدرك","القوات المسلحة","الجيش","القيادة","المخابرات",

  # public agencies / official bodies (common)
  "المندوبية","المفوضية","الهيئة","المجلس الوطني","المجلس الأعلى","مؤسسة عمومية","الوكالة","المرصد","اللجنة","اللجان",
  "وزارة الثقافة","وزارة التربية","وزارة التعليم","وزارة الصحة","وزارة الداخلية",

  # official discourse markers
  "بلاغ","بيان","تصريح رسمي","مصدر رسمي","وفق\\s+بلاغ","حسب\\s+بلاغ","أفاد\\s+بلاغ",
  "قرار","مرسوم","منشور","قانون","مشروع\\s+قانون","مذكرة"
)

```

```{r}
inst_regex <- str_c(inst_terms, collapse = "|")
# Combine all institutional terms into a single regex pattern to match any of them in the text
```

```{r}
# Build a single text field by concatenating Title + Body (handling missing values),
# then count how many institutional keywords appear (inst_hits),
# and flag the article as "institutional" if it contains at least one hit.
hespress_culture <- hespress_culture %>%
  mutate(
    text_all = str_c(coalesce(Title, ""), " ", coalesce(Body, "")),
    inst_hits = str_count(text_all, inst_regex),
    institutional_article = inst_hits > 0
  )

```

```{r}
# Check how many articles contain at least one institutional keyword,
# and summarize the distribution of keyword counts per article.
table(hespress_culture$institutional_article)
summary(hespress_culture$inst_hits)

```

So, **a majority of Hespress culture articles contain at least one institutional keyword** (i.e., they get flagged as “institutional” by your dictionary rule). That supports the idea that *institutional language is common* even in the culture section.

-   A lot of articles have **0 hits** (consistent with the 3,233 FALSE). Among the rest, the typical institutional article has **low counts**: the median is **1** and 75% of articles have **≤ 2** hits.The **mean (\~2)** is higher than the median because there’s a **right tail**: a smaller number of articles have **many hits**, including one extreme case with **68**. That likely reflects either: a very institution-heavy piece (policy/education/cultural administration), or repeated mentions of the same term / name / entity.

```{r}
# Compute article length (approx. word count), then calculate institutional keyword density
# as hits per 1,000 words (to normalize for article length).
hespress_culture <- hespress_culture %>%
  mutate(
    n_words = str_count(text_all, "\\S+"),
    institutional_density = ifelse(n_words > 0, inst_hits / n_words * 1000, 0)  # per 1,000 words
  )

```

```{r}
summary(hespress_culture$institutional_density)

```

The institutional density ranges from **0 to 72.7 institutional terms per 1,000 words**, with a **median of 2.51** and a **mean of 6.01**. The large gap between the median and the mean indicates a **strong right-skewed distribution**: most cultural articles contain **very few institutional references**, while a smaller subset is **highly saturated with institutional language**. The first quartile at **0** confirms that at least 25% of articles contain no institutional keywords at all.

```{r}
med_inst <- median(hespress_culture$institutional_density, na.rm = TRUE)

hespress_culture <- hespress_culture %>%
  mutate(
    institutional_high = institutional_density > med_inst
  )

table(hespress_culture$institutional_high)
```

Using the median as a cutoff yields a nearly **perfectly balanced split** between articles with **low institutional density (3,907)** and **high institutional density (3,902)**. This median-based dichotomization ensures comparability between groups and avoids bias introduced by extreme values. Substantively, it allows you to contrast cultural articles that are relatively **institution-light** with those that are more **institutionally inflected**, while keeping sample sizes symmetrical for downstream analysis.

```{r}
hespress_culture %>%
  filter(institutional_article) %>%
  select(doc_id, Title, inst_hits, institutional_density) %>%
  arrange(desc(inst_hits)) %>%
  slice_head(n = 10)

```

This table shows the ten cultural articles with the highest number of institutional keyword occurrences. These articles exhibit exceptionally high institutional saturation, with **29 to 68 institutional hits** and densities ranging from **about 21 to nearly 60 terms per 1,000 words**. Compared to the corpus median (2.5 per 1,000 words), these cases represent clear outliers, indicating that a small subset of cultural articles is heavily structured around institutional or formal language. This confirms that while most cultural reporting contains few institutional references, institutional framing can become dominant in specific articles.

Now, back to reuploading our ready to go sentiment analysis dataset.

```{r}
library(dplyr)
library(readr)

sentiment_df <- read_csv("hespress_sentiment_transformer.csv")

View(sentiment_df)
```

```{r}
#we merge with our existing dataset
hespress_culture <- hespress_culture %>%
  left_join(sentiment_df, by = "doc_id")
```

```{r}
#checking for NAs and such
summary(hespress_culture$sentiment_score)
sum(is.na(hespress_culture$sentiment_score))

```

#### **Quick descriptive check: Binary institutional and density proxy**

A\) Binary institutional proxy

```{r}
hespress_culture %>%
  group_by(institutional_article) %>%
  summarise(
    mean_sentiment = mean(sentiment_score, na.rm = TRUE),
    sd_sentiment   = sd(sentiment_score, na.rm = TRUE),
    n = n()
  )

```

Cultural articles that contain at least one institutional keyword have, on average, **lower sentiment scores** than those without institutional references. Non-institutional articles show a slightly positive mean sentiment, while institutional articles cluster closer to neutral, with similar levels of dispersion across both groups.

B\) Density proxy (binned view)

```{r}
hespress_culture %>%
  mutate(inst_bin = ntile(institutional_density, 5)) %>%
  group_by(inst_bin) %>%
  summarise(
    mean_sentiment = mean(sentiment_score, na.rm = TRUE),
    n = n()
  )


```

When institutional density is divided into five bins, average sentiment shows a **gradual shift toward neutrality** as institutional language becomes more dense. Articles in the lowest-density bin exhibit the most positive mean sentiment, while higher-density bins display progressively lower average sentiment scores, clustering around zero. Sample sizes are balanced across bins, indicating that this pattern is not driven by unequal group sizes.

#### T-tests and Linear Model

A Welch two-sample t-test indicates a statistically significant difference in average sentiment between institutional and non-institutional culture articles (t = 10.08, p \< .001). Non-institutional articles display a slightly more positive mean sentiment (M = 0.12) than institutional articles (M ≈ 0). However, the magnitude of this difference is small, suggesting that institutionalization primarily corresponds to a neutralization of tone rather than a strong shift toward negative sentiment.

```{r}
t.test(
  sentiment_score ~ institutional_article,
  data = hespress_culture
)

```

**Regression**

A linear regression of article-level sentiment scores on institutional density reveals a **negative and statistically significant association** between the two variables (β = −0.0031, *p* \< .001). Substantively, this coefficient indicates that an increase of one institutional reference per 1,000 words is associated with a **very small decrease in predicted sentiment**, implying that articles with denser institutional language tend to express sentiment closer to neutrality. The positive intercept (β ≈ 0.062) suggests that, in the absence of institutional references, cultural articles exhibit mildly positive average sentiment.

Despite statistical significance, the **magnitude of the effect is limited**. The model explains less than **0.3% of the total variance** in sentiment scores (R² ≈ 0.003), indicating that institutional density accounts for only a small fraction of sentiment variation across articles. This low explanatory power is consistent with earlier descriptive results showing substantial overlap in sentiment distributions across institutional-density categories.

Taken together, the findings suggest that institutional framing in cultural reporting is associated with **subtle stylistic shifts toward neutral tone**, rather than pronounced changes in emotional valence. The relationship appears gradual and monotonic, aligning with the binned and binary analyses, but should be interpreted as a **weak association** reflecting differences in register and framing rather than strong affective content. As such, institutional density functions as a modest stylistic correlate of sentiment rather than a primary driver of emotional expression in cultural articles.

```{r}
model1 <- lm(
  sentiment_score ~ institutional_density,
  data = hespress_culture
)

summary(model1)

```

When controlling for article length, institutional density remains negatively associated with sentiment (β = −0.005, p \< .001). Longer articles are themselves associated with lower sentiment scores (β = −0.0005, p \< .001), reflecting the accumulation of neutral and informational language. Importantly, the effect of institutional density persists net of article length, suggesting that institutional framing contributes to sentiment neutralization beyond differences in text length. The inclusion of this control substantially improves model fit (R² = 0.066), though the overall explanatory power remains modest.

```{r}
model2 <- lm(
  sentiment_score ~ institutional_density + n_words,
  data = hespress_culture
)

summary(model2)

```

```{r}
library(ggplot2)

ggplot(hespress_culture, aes(x = institutional_density, y = sentiment_score)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  labs(
    title = "Institutional alignment and sentiment tone in cultural articles",
    x = "Institutional density (mentions per 1,000 words)",
    y = "Sentiment score"
  ) +
  theme_minimal()

```

## Hypothesis 2

```{r}
# Load libraries (or packages):
library(tidyverse) 
library(dplyr)

#Load the datasets:
hespress <- read.csv("~/DAT505/Semester assignment/Hespress.ma.csv/Hespress.ma.csv")
akhbarona <- read.csv("~/DAT505/Semester assignment/Hespress.ma.csv/Akhbarona.ma.csv")

hibapress <- read.csv("~/DAT505/Semester assignment/Hespress.ma.csv/Hibapress.com.csv")

le360 <- read.csv("~/DAT505/Semester assignment/Hespress.ma.csv/Le360.com.csv")
```
